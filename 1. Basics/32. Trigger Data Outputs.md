# 32. Trigger Data Outputs

Canonical documentation for 32. Trigger Data Outputs. This document defines concepts, terminology, and standard usage.

## Purpose
Trigger Data Outputs serve as the primary information bridge between an initiating event (the trigger) and the subsequent logic or actions in a workflow, pipeline, or automated system. The purpose of defining these outputs is to ensure that downstream processes receive the necessary context, state, and metadata required to execute correctly. 

By standardizing how data is emitted at the moment of activation, systems can maintain decoupling while ensuring that the "contract" between the event source and the consumer is preserved. This addresses the problem of data fragmentation and the "black box" nature of event-driven architectures.

> [!NOTE]
> This documentation is intended to be implementation-agnostic and authoritative.

## Scope
Clarify what is in scope and out of scope for this topic.

**In scope:**
* **Data Structure:** The organization of information emitted by a trigger.
* **Payload Types:** The nature of the data (e.g., full state vs. delta).
* **Metadata and Context:** Information about the event itself, rather than the subject of the event.
* **Schema Consistency:** The theoretical requirement for predictable output formats.

**Out of scope:**
* **Transport Protocols:** Specific methods of moving data (e.g., Webhooks, MQTT, AMQP).
* **Vendor-Specific Syntaxes:** Specific JSON paths or liquid templating used by individual iPaaS or cloud providers.
* **Action Logic:** What happens after the data is received.

## Definitions
| Term | Definition |
|------|------------|
| **Trigger** | A specific condition or event that initiates a process or workflow. |
| **Payload** | The primary data content emitted by the trigger, usually representing the object that changed. |
| **Metadata** | Data about the data; information describing the event's origin, timestamp, and unique identifiers. |
| **Schema** | The structural definition (blueprint) that dictates what fields and data types the trigger output will contain. |
| **Contextual Data** | Supplemental information provided by the trigger environment (e.g., user permissions, environment variables). |
| **Event Envelope** | The combined structure of Metadata and Payload used to transport trigger data. |

## Core Concepts

### 1. The Event Envelope
Trigger data is rarely sent as a raw value. It is typically wrapped in an "envelope" that contains two distinct parts:
*   **Header/Metadata:** Information required for routing and auditing (e.g., `event_id`, `timestamp`, `source`).
*   **Body/Payload:** The actual data relevant to the trigger (e.g., `customer_email`, `order_total`).

### 2. Immutability
Once a trigger has fired, its data output is considered immutable. The output represents a "snapshot in time" of the state that caused the trigger. Downstream processes should treat this data as a historical record of the initiation state.

### 3. Schema Enforcement
For a trigger to be useful in automated systems, its output must follow a predictable schema. This allows downstream actions to map specific fields (e.g., "User ID") to their own inputs without manual intervention for every execution.

## Standard Model
The standard model for Trigger Data Outputs follows a hierarchical structure:

1.  **Event Identification:** A unique UUID and a timestamp (ISO 8601) to ensure traceability and idempotency.
2.  **Source Attribution:** Information identifying which system or component generated the trigger.
3.  **Subject State:**
    *   **Full Object:** The entire state of the entity (e.g., the full User record).
    *   **Reference:** A pointer or ID to the entity (e.g., `user_id`), requiring the consumer to fetch more data if needed.
4.  **Triggering Condition:** The specific change that caused the trigger (e.g., "Status changed from 'Pending' to 'Active'").

## Common Patterns

### The "Fat" Payload Pattern
The trigger outputs all available data related to the event. 
*   *Advantage:* Downstream systems do not need to make additional API calls to the source.
*   *Disadvantage:* Can lead to heavy network loads and potential data privacy concerns (over-sharing).

### The "Thin" (Reference) Pattern
The trigger outputs only the unique identifier of the affected object and the event type.
*   *Advantage:* Highly secure and lightweight.
*   *Disadvantage:* Requires downstream systems to have authentication and logic to "call back" to the source for details.

### The Delta Pattern
The trigger outputs only the specific fields that changed, often including the "before" and "after" values.
*   *Advantage:* Ideal for synchronization tasks and audit logs.

## Anti-Patterns

*   **Dynamic Schemas:** Emitting different data structures for the same trigger type based on the data content. This breaks downstream consumers.
*   **Sensitive Data Leakage:** Including PII (Personally Identifiable Information) or credentials in trigger outputs that are sent over unencrypted or logged channels.
*   **Circular Triggers:** Designing trigger outputs that, when processed, immediately cause the same trigger to fire again without a termination condition.
*   **Ambiguous Timestamps:** Providing timestamps without time zone offsets (e.g., "12:00 PM" instead of "2026-01-16T12:00:00Z").

## Edge Cases

*   **Race Conditions:** When a trigger fires, but by the time the downstream system receives the "Thin" payload and calls back for data, the data has changed again.
*   **Payload Size Limits:** Large objects (e.g., high-resolution images or massive JSON arrays) may exceed the maximum allowable size for a trigger output, requiring a "Reference" pattern instead.
*   **Batch Triggers:** When multiple events occur simultaneously, the system must decide whether to emit multiple individual outputs or a single array-based output.
*   **Deleted Entities:** When a trigger is fired by a "Delete" action, the output must contain enough cached data to be useful, as the source object no longer exists to be queried.

## Related Topics
*   **31. Event-Driven Architecture:** The broader architectural style.
*   **33. Data Mapping and Transformation:** How trigger outputs are modified for downstream use.
*   **40. Idempotency in Distributed Systems:** Ensuring that processing the same trigger output twice does not cause errors.
*   **Schema Registry:** A centralized service for managing trigger output definitions.

## Change Log
| Version | Date | Description |
|---------|------|-------------|
| 1.0 | 2026-01-16 | Initial AI-generated canonical documentation |