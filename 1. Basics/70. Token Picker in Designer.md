# 70. Token Picker in Designer

Canonical documentation for 70. Token Picker in Designer. This document defines concepts, terminology, and standard usage.

## Purpose
The Token Picker is a specialized user interface component designed to facilitate the selection and insertion of dynamic variables—referred to as "tokens"—into configuration fields within a design environment. Its primary purpose is to abstract the complexity of underlying data structures, allowing users to map dynamic data to static inputs without requiring manual syntax entry or deep knowledge of the system's data schema.

By providing a visual interface for data binding, the Token Picker ensures data integrity, reduces syntax errors, and enables non-technical users to build complex, data-driven logic.

> [!NOTE]
> This documentation is intended to be implementation-agnostic and authoritative.

## Scope
**In scope:**
* **Interaction Models:** How users discover, filter, and select tokens.
* **Data Representation:** How tokens are presented (e.g., labels, types, and paths).
* **Contextual Awareness:** How the available tokens change based on the current scope or state of the designer.
* **Validation Logic:** The theoretical constraints of token compatibility.

**Out of scope:**
* **Specific Vendor Implementations:** UI frameworks (React, Vue) or specific product instances (e.g., Salesforce, Zapier).
* **Backend Resolution Engines:** The specific code that replaces a token with a value at runtime.
* **Storage Formats:** Whether tokens are stored as JSON, XML, or plain text.

## Definitions
| Term | Definition |
|------|------------|
| **Token** | A symbolic placeholder representing a dynamic value that will be resolved at runtime. |
| **Designer** | The visual environment where configurations, workflows, or interfaces are constructed. |
| **Context** | The set of data available to the Token Picker based on the current step, location, or scope within the Designer. |
| **Namespace** | A logical grouping of tokens, often representing a specific data source or category (e.g., "System Variables," "User Profile"). |
| **Resolution** | The process of replacing a token with its actual value during execution. |
| **Type Safety** | The mechanism that ensures a selected token's data type matches the expected input type of the target field. |

## Core Concepts

### 1. Data Mapping and Abstraction
The Token Picker acts as a translation layer between the raw data model and the user interface. It hides technical paths (e.g., `$.request.body.user[0].id`) behind human-readable labels (e.g., `User ID`).

### 2. Contextual Availability
Tokens are not static; the list of available tokens is determined by the "upstream" data. In a sequential process, only data generated in preceding steps or global constants should be available for selection.

### 3. Visual Encapsulation
Tokens are typically rendered as "pills" or distinct visual blocks within a text field. This distinguishes them from static text and indicates that they are atomic units that cannot be partially edited.

### 4. Metadata Enrichment
A robust Token Picker provides metadata about each token, including:
* **Data Type:** (String, Integer, Boolean, Object, Array).
* **Sample Value:** A preview of what the data might look like at runtime.
* **Origin:** Where the data comes from (e.g., "Trigger Step").

## Standard Model
The standard model for a Token Picker implementation follows a three-tier architecture:

1.  **The Discovery Layer:** A searchable, categorized list or tree structure where users browse available tokens.
2.  **The Selection Layer:** The mechanism (click, drag-and-drop, or autocomplete) used to move a token from the list into the target field.
3.  **The Presentation Layer:** The visual representation of the token within the input field, maintaining a link to the underlying data path while displaying a user-friendly label.

## Common Patterns

### Search-First Discovery
In systems with high data density, the Token Picker defaults to a search interface, allowing users to filter hundreds of potential tokens by name or description.

### Hierarchical Tree Navigation
Tokens are organized by their source or object structure. Users can drill down into nested objects (e.g., `Order` -> `Customer` -> `Email`) to find specific attributes.

### Type-Filtered Selection
The Token Picker automatically filters the available tokens to match the expected input type. For example, if a field requires a "Date," only date-type tokens are displayed or highlighted.

### Inline Autocomplete
Triggered by a specific character (often `{{` or `{`), this pattern allows users to search for and insert tokens without leaving the keyboard or opening a separate modal.

## Anti-Patterns

*   **Flat Lists for Complex Data:** Presenting hundreds of tokens in a single, unorganized list, making discovery impossible.
*   **Path Exposure:** Displaying raw technical paths (e.g., `var_123_abc`) instead of human-readable labels, which alienates non-technical users.
*   **Stale Tokens:** Allowing the selection of tokens that are no longer available in the current context or have been deleted from upstream steps.
*   **Lack of Type Validation:** Allowing a "List" token to be inserted into a "Boolean" field without warning or transformation.

## Edge Cases

*   **Circular References:** A scenario where a token's value depends on the field it is currently being inserted into. The Token Picker must detect and prevent these loops.
*   **Deeply Nested Arrays:** Handling tokens within arrays where an index or "map" function is required to resolve a specific value.
*   **Null/Empty States:** How the Token Picker behaves when a data source is connected but currently contains no data or schema information.
*   **Token-in-Token:** The complexity of nesting one token inside the configuration of another (e.g., using a token to define the key for a lookup in another token).

## Related Topics
*   **Data Transformation:** The process of modifying a token's value (e.g., formatting a date) after selection.
*   **Expression Builders:** Advanced interfaces that combine tokens with logic and operators.
*   **Schema Inference:** The technology used to determine which tokens are available based on sample data or API definitions.

## Change Log
| Version | Date | Description |
|---------|------|-------------|
| 1.0 | 2026-01-16 | Initial AI-generated canonical documentation |