# 33. Near Real Time Triggering

Canonical documentation for 33. Near Real Time Triggering. This document defines concepts, terminology, and standard usage.

## Purpose
Near Real Time (NRT) Triggering addresses the requirement for systems to respond to events or data changes with minimal latency, typically ranging from milliseconds to a few seconds. It exists to bridge the gap between traditional **Batch Processing** (which suffers from high latency) and **Hard Real-Time Systems** (which require deterministic, microsecond-level responses and specialized hardware/OS constraints). 

The primary goal of NRT Triggering is to enable business agility and operational responsiveness by ensuring that downstream actions are initiated as soon as the necessary input data becomes available and is minimally processed.

> [!NOTE]
> This documentation is intended to be implementation-agnostic and authoritative.

## Scope
Clarify what is in scope and out of scope for this topic.

**In scope:**
* **Event-Driven Activation:** Mechanisms that initiate processes based on state changes or message arrivals.
* **Latency Boundaries:** Theoretical definitions of "Near Real Time" versus other processing cadences.
* **Triggering Logic:** The criteria and filters used to determine if an action should be executed.
* **Asynchronous Orchestration:** The decoupling of the event source from the triggered action.

**Out of scope:**
* **Specific Vendor Implementations:** (e.g., AWS Lambda, Kafka Streams, Azure Functions).
* **Hard Real-Time Determinism:** Systems where a late response is considered a total system failure (e.g., automotive braking systems).
* **Data Persistence Strategies:** The specific mechanics of how data is stored, focusing instead on how the *trigger* is fired.

## Definitions
Provide precise definitions for key terms.

| Term | Definition |
|------|------------|
| **Event** | A significant change in state or a discrete record of an occurrence at a specific point in time. |
| **Trigger** | A functional gate or condition that, when met, initiates a secondary process or workflow. |
| **Latency** | The time elapsed between the occurrence of an event and the initiation of the triggered action. |
| **Ingestion** | The process of receiving and potentially buffering events before they are evaluated by a trigger. |
| **Idempotency** | The property of a system where multiple identical requests have the same effect as a single request. |
| **Backpressure** | A resistance or signal sent upstream when the triggering system cannot keep up with the rate of incoming events. |
| **Throughput** | The volume of events a triggering system can evaluate and execute within a given time frame. |

## Core Concepts

### 1. The Latency Continuum
NRT Triggering occupies the middle ground of the latency spectrum. Unlike batch processing, which waits for a volume or time threshold, NRT attempts to process events individually or in micro-batches as they arrive.

### 2. Event-Driven Architecture (EDA)
NRT Triggering is the functional engine of EDA. It relies on the "Push" model, where the source of the data notifies the consumer, rather than the consumer "Pulling" (polling) for updates.

### 3. Decoupling
A fundamental concept of NRT is the separation of the **Producer** (the entity generating the event) from the **Consumer** (the entity performing the action). This is usually mediated by an event bus or message broker to ensure that the producer is not blocked by the execution time of the trigger.

### 4. Non-Determinism
Unlike hard real-time systems, NRT systems are generally non-deterministic regarding exact timing. While they aim for "as fast as possible," they do not guarantee execution within a specific microsecond window, allowing for variability in network and compute performance.

## Standard Model

The standard model for NRT Triggering follows a linear progression of four stages:

1.  **Observation:** An event occurs within a source system (e.g., a user clicks a button, a sensor detects a temperature change).
2.  **Ingestion & Transport:** The event is captured and moved to a processing layer. This layer often includes a buffer to handle spikes in volume.
3.  **Evaluation (The Trigger):** The system applies logic to the event. If the event meets specific criteria (e.g., "Price > 100"), the trigger fires.
4.  **Execution:** The downstream action is initiated (e.g., sending a notification, updating a database, calling an API).

## Common Patterns

### Fan-Out
A single event triggers multiple independent downstream actions simultaneously. This is common in microservices where one event (e.g., "Order Placed") triggers inventory, billing, and shipping services.

### Debouncing / Throttling
In scenarios where events occur in rapid succession (e.g., a sensor flickering), NRT systems use debouncing to wait for a period of inactivity before triggering, or throttling to limit the number of triggers within a specific window.

### Dead Letter Queue (DLQ)
When a trigger fails to execute the downstream action (due to errors or timeouts), the event is moved to a DLQ for manual inspection or automated retry, ensuring no events are lost in the NRT flow.

### Content-Based Routing
The trigger logic inspects the payload of the event to determine which downstream path to take.

## Anti-Patterns

### High-Frequency Polling
Attempting to achieve NRT by polling a database or API every few milliseconds. This creates unnecessary overhead and scales poorly compared to push-based triggers.

### Synchronous Chaining
Making the producer wait for the triggered action to complete before continuing. This negates the benefits of NRT by introducing "Head-of-Line Blocking," where one slow action stalls the entire event pipeline.

### Lack of Idempotency
Designing triggers that produce different results if an event is processed twice. In NRT systems, network retries are common; triggers must be able to handle duplicate events gracefully.

### "Big Ball of Mud" Logic
Embedding complex business logic directly within the trigger evaluation layer. Triggers should be "thin" and primarily responsible for routing and initiation.

## Edge Cases

### Thundering Herd
A scenario where a single event (or a system recovery) triggers a massive number of downstream actions simultaneously, potentially overwhelming the infrastructure.

### Out-of-Order Delivery
In distributed systems, Event B might arrive before Event A, even if Event A happened first. NRT triggers must account for sequence if the order of operations is critical.

### Network Partitions
If the triggering system is separated from the execution system by a network failure, the system must decide whether to buffer events (increasing latency) or drop them (losing data).

### Clock Skew
When triggers rely on timestamps from different distributed machines, slight variations in system clocks can lead to incorrect logical ordering or expiration of events.

## Related Topics
* **Event-Driven Architecture (EDA):** The overarching architectural style.
* **Message Queuing:** The underlying transport mechanism for NRT.
* **Stream Processing:** The continuous processing of data in motion, often used to feed NRT triggers.
* **Complex Event Processing (CEP):** Identifying patterns across multiple events to fire a single trigger.

## Change Log

| Version | Date | Description |
|---------|------|-------------|
| 1.0 | 2026-01-16 | Initial AI-generated canonical documentation |