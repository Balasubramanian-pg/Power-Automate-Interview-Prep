# 44. Filtering Result for Failures

## 1. Flow Overview
- **Flow Name**: Failure Isolation and Exception Reporting Pattern
- **Business Problem Statement**: In high-volume batch processing or loops, a single failure often goes unnoticed if the overall flow succeeds, or the entire flow terminates prematurely, leaving the status of individual records unknown.
- **Business Impact / Value**: Ensures 100% data integrity by identifying and isolating failed records for automated retry or manual intervention. It reduces "silent failures" and provides a clean audit trail for compliance.
- **Trigger Type**: Automated (typically following a batch processing event)
- **Trigger Source**: Data Source (e.g., SQL, SharePoint, Dataverse) or a Parent Flow
- **Systems / Connectors Involved**: Data Operations, Control Logic, Notification Services (Email/Teams), Logging Systems (Azure Monitor/Log Analytics)
- **Expected Run Frequency**: Per batch execution or on-demand
- **Estimated Data Volume**: 100 - 10,000 records per batch

## 2. Trigger Design
- **Trigger Connector & Action**: Recurrence or When an item is created/modified
- **Why This Trigger Was Chosen**: This pattern is usually embedded within a larger integration flow or triggered as a child flow to process the output of a "Try/Catch" block.
- **Trigger Conditions Used**: No
- **Trigger Condition Logic**: N/A
- **Polling vs Event-Based**: Event-based (triggered by the completion of a processing scope).
- **How Unnecessary Runs Are Avoided**: The filtering logic only executes if the preceding "Process" scope returns a status other than 'Succeeded' for one or more items.

## 3. End-to-End Flow Narrative
The flow begins by executing a series of actions (the "Process Scope") against a collection of data. Within this scope, multiple records are processed (e.g., updated in a CRM or sent to an API). 

Once the processing scope completes—regardless of whether it succeeded or failed—the "Filter Results" logic is triggered using a "Run After" configuration. The flow uses a Data Operation to inspect the execution metadata of the previous actions. It specifically looks for status codes or error messages associated with each record.

The flow then applies a filter to the result set to isolate only those records where the status equals 'Failed' or 'TimedOut'. If the resulting array is not empty, the flow proceeds to log these specific failures to a centralized error table and sends a consolidated notification to the administrator. This prevents the flow from failing entirely while ensuring every error is captured.

## 4. Key Actions and Connectors
Document only the actions that influence logic, performance, or reliability.

| Action Name | Connector | Purpose | Key Inputs | Key Outputs | Why This Action |
|------------|-----------|---------|------------|-------------|----------------|
| **Process_Scope** | Control | Groups processing actions | Data Array | Scope Status | To encapsulate actions for collective result analysis. |
| **Get_Scope_Results** | Data Operations (Compose) | Captures the output of the scope | `result('Process_Scope')` | JSON Array of action metadata | Essential for accessing the status of every action inside the scope. |
| **Filter_Failures** | Data Operations (Filter Array) | Isolates failed items | Output of Get_Scope_Results | Array of Error Objects | Efficiently removes successful items without using a loop. |
| **Check_Error_Count** | Control (Condition) | Determines if errors exist | `length(body('Filter_Failures'))` | Boolean | Prevents unnecessary notification/logging steps if no errors occurred. |

## 5. Control Logic and Flow Structure
- **Conditions Used**: Used to check if the filtered "Failure Array" contains any items before proceeding to error handling.
- **Switch Statements**: Occasionally used if different error types (e.g., 401 vs 500) require different routing.
- **Loops (Apply to each / Do until)**: Used *after* filtering to iterate through only the failed items for logging.
- **Nested Loops**: No; filtering is done via Data Operations to avoid the performance hit of nested loops.
- **Parallel Branches**: Used to run the "Success" path and "Failure" path simultaneously or to handle logging in parallel with notifications.
- **Scope Usage**: Critical. A "Try" scope contains the main logic, and a "Catch" scope contains the filtering logic.

## 6. Error Handling and Monitoring
- **Anticipated Failure Scenarios**: API Throttling (429), Timeout (408), Schema Mismatch, or Authentication expiry.
- **Try Scope Logic**: Contains the primary business logic and data processing.
- **Catch Scope Logic**: Contains the `Filter Array` action configured to run only if the Try scope fails or times out.
- **Finally Scope Logic**: Used for cleanup or to update a "Batch Header" status regardless of individual item success.
- **Run After Configuration**: The Filter action is set to run if the previous scope has **Succeeded, Failed, or Timed Out**.
- **Failure Notification Method**: A single summary email/Teams message containing a table of all failed records.
- **Logging Strategy**: Failed items are written to a persistent store (SQL/Log Analytics) with the Correlation ID.
- **How to Debug a Failed Run**: Inspect the output of the `Filter Array` action to see the raw JSON error response from the target system.

## 7. Data Handling and Expressions
- **Variables Used**: `varErrorList` (Array) to store formatted error messages.
- **Key Expressions**: 
    - `result('Scope_Name')`: Retrieves the status of all actions in a scope.
    - `item()?['outputs']?['body']?['error']?['message']`: Extracts the specific error text within a Filter Array.
    - `empty(body('Filter_Array'))`: Checks if any failures were found.
- **Data Operations (Select / Filter array / Compose)**: `Filter Array` is used instead of a loop to identify failures, which is significantly faster. `Select` is used to map the messy "result" object into a clean table for reporting.
- **Why Expressions Were Used Instead of Actions**: Using `result()` and `Filter Array` is an O(n) operation in memory, whereas looping through every item and using a Condition action is O(n) and incurs significant latency due to action overhead.

## 8. Performance and Scalability
- **Known Bottlenecks**: The `result()` function can produce a very large JSON object if the scope contains many actions and many iterations.
- **Loop Optimization Strategy**: Use "Filter Array" to reduce the dataset to only failures before entering any "Apply to Each" loop for logging.
- **Pagination Handling**: Ensure the initial data retrieval uses pagination to handle large datasets before the filtering logic is applied.
- **Concurrency Control**: If processing in a loop, enable concurrency to speed up the "Try" scope, as the filtering logic can handle unordered results.
- **What Breaks at Higher Data Volumes**: Memory limits of the orchestration engine may be reached if the `result()` output exceeds 100MB.
- **Redesign Approach for Scale**: For extremely large volumes, offload the filtering to a database (e.g., SQL query for "Status = 'Error'") rather than filtering in the flow engine.

## 9. Security and Governance
- **Connection Type (Personal / Service Account)**: Service Account (Principal) to ensure continuity and centralized logging access.
- **Environment Strategy**: Deployed in a Production environment with restricted access to run history.
- **Secrets Handling**: Error messages are scrubbed for PII (Personally Identifiable Information) or credentials before being sent via email.
- **DLP Considerations**: Ensure the "Notification" connector (e.g., SMTP or Teams) is in the same data group as the "Data Source" connector.
- **Access Control Notes**: Only System Administrators should have access to the error logs generated by this flow.

## 10. Testing and Validation
- **Test Scenarios Covered**: 
    1. All items succeed (Filter should return empty).
    2. All items fail (Filter should return all).
    3. Partial success (Filter should return only specific failures).
- **Edge Cases Considered**: 
    - Scope times out before all items are processed.
    - The error message itself is null or malformed.
- **Failure Testing**: Manually forcing a 401 Unauthorized by temporarily changing a secret to ensure the filter catches the error.
- **Rerun / Recovery Strategy**: The flow provides a "Failed Items" list which can be used as the input for a "Retry Flow."

## 11. Interview Question Mapping
- **Explain This Flow in 2–3 Minutes**: "I implemented a robust error-handling pattern that uses the `result()` expression to capture the outcome of every action within a processing scope. Instead of letting the flow fail on the first error, I use a 'Filter Array' action to isolate only the failed records. This allows the flow to continue, log the specific errors for audit, and notify the team with a consolidated report of exactly what went wrong and why."
- **How Failures Are Handled**: "Failures are handled by a 'Catch' scope configured with 'Run After' settings. We filter the scope's output for 'Failed' statuses, format those into a HTML table, and log them to a database for later reprocessing."
- **How Performance Is Optimized**: "By using the `Filter Array` data operation rather than looping through every item with a condition, I reduced the processing time for error evaluation from minutes to seconds."
- **One Trade-Off Made**: "I traded off granular real-time alerts for a summary report. While real-time alerts are faster, they cause 'notification fatigue' during large batch failures. A filtered summary is more actionable."

## 12. Lessons Learned
- **Initial Issues**: Initially, I used a variable inside a loop to track failures, but this caused race conditions when concurrency was enabled.
- **Improvements Made**: Switched to the `result()` expression and `Filter Array` pattern, which is thread-safe and supports high concurrency.
- **What I Would Do Differently Now**: I would implement a "Hash" check to ensure that if the same error occurs 1,000 times (e.g., a database is down), the notification only sends the error once with a count, rather than listing 1,000 identical rows.

> [!IMPORTANT]
> Always ensure the "Run After" settings of the action following your "Try" scope include "Has Failed" and "Has Timed Out," otherwise the filtering logic will never execute when you need it most.

> [!TIP]
> Use the `Select` action after `Filter Array` to pick only the `Action Name`, `Error Message`, and `Timestamp`. This makes the final report much more readable for non-technical stakeholders.